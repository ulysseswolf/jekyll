---
layout: post
title: "Pandas"
description: ""
categories: 
- python
tags: [python]
---
{{ page.title }}
================

{% highlight python%}
# add row to dataframe
import pandas as pd

data = {'name': ['Somu', 'Kiku', 'Amol', 'Lini'],
	'physics': [68, 74, 77, 78],
	'chemistry': [84, 56, 73, 69],
	'algebra': [78, 88, 82, 87]}

	
#create dataframe
df_marks = pd.DataFrame(data)
print('Original DataFrame\n------------------')
print(df_marks)

new_row = {'name':'Geo', 'physics':87, 'chemistry':92, 'algebra':97}
#append row to the dataframe
df_marks = df_marks.append(new_row, ignore_index=True)

print('\n\nNew row added to DataFrame\n--------------------------')
print(df_marks)

# set column value on condition
df['color'] = np.where(df['Set']=='Z', 'right', 'wrong')

# assign columns
df.assign(Name='abc', Sex='male', Age=18)

# drop None colum rows
import pandas as pd
df = df[pd.notnull(df['EPS'])]
# or 
df.dropna(subset = ['column_name'], inplace=True)
filtered_df = df[df['column_name'].notnull()]

# to_sql if_exists
data_frame.to_sql(table_name, engine, if_exists='append', chunksize=1000)

pd.merge(df1, df2, on=['A', 'B'])
# return only the values where A and B exist in both dataframes as the default merge type is an inner merge.

# get value from a cell
df.iloc[0] #first row
df.iloc[0]['column']

# if_exists : {‘fail’, ‘replace’, ‘append’}, default ‘fail’
#fail: If table exists, do nothing.
#replace: If table exists, drop it, recreate it, and insert data.
#append: If table exists, insert data. Create if does not exist.

# left join and update left column 
# https://stackoverflow.com/questions/30045086/pandas-left-join-and-update-existing-column
# use merge() between left and right with how='left' on 'a' column
In [74]: final = left.merge(right, on='a', how='left')
In [75]: final
Out[75]:
   a  b  c_x  c_y   d
0  1  4    9    7  13
1  2  5   10    8  14
2  3  6   11    9  15
3  4  7   12  NaN NaN
# Replace NaN value from c_y with c_x value
In [76]: final['c'] = final['c_y'].fillna(final['c_x'])
In [77]: final
Out[77]:
   a  b  c_x  c_y   d   c
0  1  4    9    7  13   7
1  2  5   10    8  14   8
2  3  6   11    9  15   9
3  4  7   12  NaN NaN  12
# Drop unwanted columns, and you have the result
In [79]: final.drop(['c_x', 'c_y'], axis=1)
Out[79]:
   a  b   d   c
0  1  4  13   7
1  2  5  14   8
2  3  6  15   9
3  4  7 NaN  12

# Convert psycopg2 DictRow query to Pandas dataframe 
curs = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
curs.execute("SELECT * FROM mytable")
data = curs.fetchall()

print type(data)
# <type 'list'>
df = pd.DataFrame([i.copy() for i in data])
# The copy() function of the DictRow class will return an actual dictionary.


DataFrame.apply(func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)
# axis = 1 把一行数据作为Series的数据结构传入给自己实现的函数中

# Checking if particular value (in cell) is NaN
In [7]: pd.isna(df.iloc[1,0])
Out[7]: True

# count 
pandas.DataFrame
Display number of rows, columns, etc.: df.info()
Get the number of rows: len(df)
Get the number of columns: len(df.columns)
Get the number of rows and columns: df.shape
Get the number of elements: df.size
Notes when specifying index
pandas.Series
Get the number of elements: len(s), s.size

# 'Timestamp' object has no attribute 'translate' 
`df[colname] = pd.to_datetime(df[colname])`

# drop column 
del df['column_name']
df.drop(['A', 'B'], axis=1)
{% endhighlight %}
